# Copyright (c) Pixie Labs, Inc.
# Licensed under the Apache License, Version 2.0 (the "License")

''' Namespaces Overview

This view lists the namespaces on the current cluster and their pod and service counts.
It also lists the high-level resource consumption by namespace.

'''

import px

bytes_per_mb = 1024.0 * 1024.0
# Window size to use on time_ column for bucketing.
window_s = 10


def namespaces_for_cluster(start_time: str):
    ''' Gets a list of namespaces in the current cluster since `start_time`.

    Args:
    @start: Start time of the data to examine.
    '''
    df = px.DataFrame(table='process_stats', start_time=start_time)
    df.service = df.ctx['service_name']
    df.pod = df.ctx['pod_name']
    df.namespace = df.ctx['namespace']
    agg = df.groupby(['service', 'pod', 'namespace']).agg()
    namespaces = agg.groupby('namespace').agg(
        pod_count=('pod', px.count),
        service_count=('service', px.count)
    )
    return namespaces


def process_stats_by_namespace(start_time: str):
    ''' Gets a summary of process stats by namespace since `start_time`.
        Computes the total I/O consumption across the namespace since `start_time`.

    Args:
    @start: Start time of the data to examine.
    '''

    df = px.DataFrame(table='process_stats', start_time=start_time)
    df.namespace = df.ctx['namespace']
    df.timestamp = px.bin(df.time_, px.seconds(window_s))

    # Convert to MB.
    df.vsize_mb = df.vsize_bytes / bytes_per_mb
    df.rss_mb = df.rss_bytes / bytes_per_mb
    df.read_mb = df.read_bytes / bytes_per_mb
    df.write_mb = df.write_bytes / bytes_per_mb
    df.rchar_mb = df.rchar_bytes / bytes_per_mb
    df.wchar_mb = df.wchar_bytes / bytes_per_mb

    df = df.groupby(['upid', 'namespace', 'timestamp']).agg(
        vsize_mb=('vsize_mb', px.mean),
        rss_mb=('rss_mb', px.mean),
        read_mb_max=('read_mb', px.max),
        read_mb_min=('read_mb', px.min),
        write_mb_max=('write_mb', px.max),
        write_mb_min=('write_mb', px.min),
        rchar_mb_max=('rchar_mb', px.max),
        rchar_mb_min=('rchar_mb', px.min),
        wchar_mb_max=('wchar_mb', px.max),
        wchar_mb_min=('wchar_mb', px.min),
    )

    # Deltas computed across 1 time window
    df.read_mb = df.read_mb_max - df.read_mb_min
    df.write_mb = df.write_mb_max - df.write_mb_min
    df.rchar_mb = df.rchar_mb_max - df.rchar_mb_min
    df.wchar_mb = df.wchar_mb_max - df.wchar_mb_min

    # For this aggregate, we sum up the values as we've already calculated the average/usage
    # for the upids already.
    df = df.groupby(['namespace', 'timestamp']).agg(
        vsize_mb=('vsize_mb', px.sum),
        rss_mb=('rss_mb', px.sum),
        read_mb=('read_mb', px.sum),
        write_mb=('write_mb', px.sum),
        rchar_mb=('rchar_mb', px.sum),
        wchar_mb=('wchar_mb', px.sum),
    )

    window_size = 1.0 * window_s
    df.read_mb_per_s = df.read_mb / window_size
    df.write_mb_per_s = df.write_mb / window_size
    df.rchar_mb_per_s = df.rchar_mb / window_size
    df.wchar_mb_per_s = df.wchar_mb / window_size

    # Finally, we get the mean value across the total time window.
    df = df.groupby('namespace').agg(
        avg_vsize_mb=('vsize_mb', px.mean),
        avg_rss_mb=('rss_mb', px.mean),
        read_mb_per_s=('read_mb_per_s', px.mean),
        write_mb_per_s=('write_mb_per_s', px.mean),
        rchar_mb_per_s=('rchar_mb_per_s', px.mean),
        wchar_mb_per_s=('wchar_mb_per_s', px.mean),
    )

    return df
